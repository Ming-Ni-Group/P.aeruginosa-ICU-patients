Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	TrimReads
	1	all
	2
Select jobs to execute...

[Wed Feb 24 17:14:17 2021]
rule TrimReads:
    input: /shared/liuhj/tonglv/process/ntfreq/test/ntfreq_file_list.txt, /shared/liuhj/tonglv/ref/ref_tonglv_AE004091.2/AE004091.2.fna
    output: /shared/liuhj/tonglv/process/ntfreq/test/out/out.txt
    jobid: 1

python /shared/liuhj/tonglv/ICU_tonglv_scripts/iSNV_calling_bwa2_AE004091.2/step6_read_ntfreq.py  -i  /shared/liuhj/tonglv/process/ntfreq/test/ntfreq_file_list.txt -r /shared/liuhj/tonglv/ref/ref_tonglv_AE004091.2/AE004091.2.fna  -o /shared/liuhj/tonglv/process/ntfreq/test/out  		-D  50 -A 5 -N 100 -F 0.02 -S 0.1 
[Wed Feb 24 17:14:50 2021]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...

[Wed Feb 24 17:14:50 2021]
localrule all:
    input: /shared/liuhj/tonglv/process/ntfreq/test/out/out.txt
    jobid: 0

[Wed Feb 24 17:14:50 2021]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /shared/liuhj/tonglv/ICU_tonglv_scripts/iSNV_calling_bwa2_AE004091.2/.snakemake/log/2021-02-24T171417.479595.snakemake.log
